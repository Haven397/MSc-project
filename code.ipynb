{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb4cc727-016b-47d7-a7ba-4fccbb33c5f0",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Import</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415d7835-90b8-410f-ae24-67772975e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9743e64-6a94-4805-bf21-a10bca51b756",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">All function</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a2695-3f43-4b95-afc7-9fe1220b2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def data_pre(companies):\n",
    "    for i in companies:\n",
    "        if 'metadata' in i.keys():\n",
    "            del i['metadata']\n",
    "        comp_name = i['name']\n",
    "        i['name'] = f\"{comp_name}_{companies.index(i)}\"\n",
    "        if not isinstance(i['equity_funding_total_usd'], int):\n",
    "            value = i['equity_funding_total_usd']\n",
    "            i['equity_funding_total_usd'] = int(value['$numberLong'])\n",
    "        if i['num_funding_rounds'] is None:\n",
    "            i['num_funding_rounds'] = 0\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f0999-0018-4acd-8264-896359ba2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The criteria to judge whether the company is successful\n",
    "def whether_success(companies):\n",
    "    for i in companies:\n",
    "        i['startup'] = 'failed'\n",
    "        if i['operating_status'] != 'closed':\n",
    "            if i['went_public_on']:\n",
    "                i['startup'] = 'success'\n",
    "            elif i['status'] == 'was_acquired' or i['status'] == 'ipo':\n",
    "                i['startup'] = 'success'\n",
    "            elif (datetime.now() - datetime.strptime(i['founded_on'], '%Y-%m-%d')).days/365 >= 7:\n",
    "                i['startup'] = 'success'\n",
    "            elif i['num_funding_rounds'] >= 7:\n",
    "                i['startup'] = 'success'\n",
    "            elif i['equity_funding_total_usd'] >= 100000000:\n",
    "                i['startup'] = 'success'\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138b218-e196-4f84-bf70-137f760a7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_nw(comps, peo):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(comps)\n",
    "    \n",
    "    peo_dict = {comp: set(p) for comp, p in zip(comps, peo)}\n",
    "    \n",
    "    def process_pairs(i, comp):\n",
    "        edges = []\n",
    "        for j in range(i+1, len(comps)):\n",
    "            same = peo_dict[comp] & peo_dict[comps[j]]\n",
    "            if same:\n",
    "                edges.append((comp, comps[j], len(same)))\n",
    "        return edges\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_pairs, i, comp) for i, comp in enumerate(comps)]\n",
    "        for future in as_completed(futures):\n",
    "            for comp1, comp2, weight in future.result():\n",
    "                if G.has_edge(comp1, comp2):\n",
    "                    G[comp1][comp2]['weight'] += weight\n",
    "                else:\n",
    "                    G.add_edge(comp1, comp2, weight=weight)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112be56-1853-4c14-85de-ba685d9a53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rate\n",
    "def success_rate(data, dict, field):\n",
    "    result = {}\n",
    "    for i in dict:\n",
    "        result[i] = 0\n",
    "        for n in data:\n",
    "            if isinstance(n[field], list):\n",
    "                if i in n[field] and n['startup'] == 'success':\n",
    "                    result[i] += 1\n",
    "            else:\n",
    "                if n[field] == i and n['startup'] == 'success':\n",
    "                    result[i] += 1\n",
    "    for k in result:\n",
    "        result[k] = result[k]/dict[k]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcffe2b-e18d-43a6-b004-66f4c6105c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate component data\n",
    "def components_data(G):\n",
    "    result = {}\n",
    "    for component in nx.connected_components(G):\n",
    "        subgraph = G.subgraph(component)\n",
    "        sub_size = len(subgraph)\n",
    "        sub_success = 0\n",
    "        for node in subgraph:\n",
    "            if G.nodes[node]['success'] == 'success':\n",
    "                sub_success += 1\n",
    "        sub_success_rate = sub_success/sub_size\n",
    "        for node in subgraph:\n",
    "            result[node] = {'component_size': sub_size, 'component_success_rate': sub_success_rate}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c31486-3213-479a-9b6f-beea18363e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis of the whole network\n",
    "def generate_data(G):\n",
    "    net_nodes = len(G.nodes())\n",
    "    net_edges = len(G.edges())\n",
    "    net_den = round(nx.density(G),4)\n",
    "    avg_cluster = round(nx.average_clustering(G),4)\n",
    "    avg_degree = round(np.mean(list(dict(G.degree()).values())),4)\n",
    "    max_degree = max(list(dict(G.degree()).values()))\n",
    "    min_degree = min(list(dict(G.degree()).values()))\n",
    "    total_strength = 0\n",
    "    for node in G.nodes():\n",
    "        node_strength = sum(data[\"weight\"] for u, v, data in G.edges(node, data=True))\n",
    "        total_strength += node_strength\n",
    "    avg_strength = round(total_strength / net_nodes, 4)\n",
    "    try:\n",
    "        net_assortativity = round(nx.degree_assortativity_coefficient(G),4)\n",
    "    except RuntimeWarning:\n",
    "        net_assortativity = None\n",
    "\n",
    "    table ={\n",
    "        \"Number of Nodes\": net_nodes,\n",
    "        \"Number of Edges\": net_edges,\n",
    "        \"Density\": net_den,\n",
    "        \"Avg Clustering Coefficient\": avg_cluster,\n",
    "        \"Avg Degree\": avg_degree,\n",
    "        \"Max Degree\": max_degree,\n",
    "        \"Min Degree\": min_degree,\n",
    "        \"Avg Strength\": avg_strength,\n",
    "        \"Assortativity\": net_assortativity}    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961cedb3-59e5-4be9-b220-4316cc36a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the features\n",
    "def generate_feature(G, data):\n",
    "    degrees = dict(G.degree())\n",
    "    # clustering = nx.clustering(G)\n",
    "    closeness = nx.closeness_centrality(G)\n",
    "    # betweenness = nx.betweenness_centrality(G)\n",
    "    # eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "    # pagerank = nx.pagerank(G)\n",
    "    \n",
    "    nodes = [node for node in G.nodes() if node not in list(nx.isolates(G))]\n",
    "    fea_info = {\n",
    "        'node_id': nodes,\n",
    "        'degree': [degrees[node] for node in nodes],\n",
    "        # 'clustering': [clustering[node] for node in nodes],\n",
    "        'closeness': [closeness[node] for node in nodes],\n",
    "        # 'betweenness': [betweenness[node] for node in nodes],\n",
    "        # 'closeness': [closeness[node] for node in nodes],\n",
    "        # 'eigenvector_centrality': [eigenvector_centrality[node] for node in nodes],\n",
    "        # 'pagerank': [pagerank[node] for node in nodes],\n",
    "        'categories': [comp['category_groups'] for comp in data if comp['name'] not in list(nx.isolates(G))]\n",
    "    }\n",
    "    df = pd.DataFrame(fea_info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f06f62-9c1d-43c4-8cec-870e593e1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "def evaluate_pred(model, X_test, y_test, y_pred, model_name):\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} does not provide probability predictions for ROC AUC Score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b1359-86bc-4177-b973-e87ff32294b8",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Data loading and preprocessing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f4d7c-463b-4470-acec-5402491f56b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/kiening/Documents/Dissertation/dissertation.cb_companies.json'\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2530959-5349-453e-ab6d-aded06f95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = whether_success(data_pre(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0083ed-39bb-4db5-821c-9d87fbb9a7db",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Network building</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c59b2-d5ad-4d2c-8ad2-e3cdfdcb04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = []\n",
    "peo = []\n",
    "\n",
    "for com in data:\n",
    "    comps.append(com['name'])\n",
    "    peo.append(list(set(com['founders']) | set(com['investors'])))\n",
    "\n",
    "unique_comps = [f\"{comp}_{i}\" for i, comp in enumerate(comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd714d-550c-4546-8b53-b45e06681bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_nw(unique_comps, peo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cef092-0a08-4621-bf6c-472af763dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw network here\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, \n",
    "        pos, \n",
    "        with_labels=False, \n",
    "        node_size=5, \n",
    "        font_size=5)\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7ebd0-763a-4260-af90-9c9a7748a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attri = {}\n",
    "for index, node in enumerate(G.nodes()):\n",
    "    node_attri[node] = {}\n",
    "    node_attri[node]['categories'] = data[index]['category_groups']\n",
    "    node_attri[node]['success'] = data[index]['startup']\n",
    "nx.set_node_attributes(G, node_attri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d30f7-094c-427b-aaaf-3a1f2993fab3",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Basic analysis of the whole network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071b73b-5216-4738-a012-1daf90611542",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = generate_data(G)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674f12f-aaf7-46cc-af3a-5f7911b785b7",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Isolated nodes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c74a2-2d1d-4d41-b9f7-ca9ec973f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolates = list(nx.isolates(G))\n",
    "iso_comps = []\n",
    "found_on = []\n",
    "funding = []\n",
    "rounds = []\n",
    "startup = []\n",
    "for i in range(len(unique_comps)):\n",
    "    if unique_comps[i] in isolates:\n",
    "        iso_comps.append(data_test[i]['name'])\n",
    "        found_on.append((datetime.now() - datetime.strptime(data_test[i]['founded_on'], '%Y-%m-%d')).days)\n",
    "        funding.append(data_test[i]['equity_funding_total_usd'])\n",
    "        rounds.append(data_test[i]['num_funding_rounds'])\n",
    "        startup.append(data_test[i]['startup'])\n",
    "iso_df = pd.DataFrame({\n",
    "    'company': iso_comps,\n",
    "    'days_since_founded': found_on,\n",
    "    'equity_funding_total_usd': funding,\n",
    "    'num_funding_rounds': rounds,\n",
    "    'startup': startup\n",
    "})\n",
    "iso_df['num_funding_rounds'] = iso_df['num_funding_rounds'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45a66e-73a8-4352-89f0-a76920d39ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random forests to judge feature importance\n",
    "X = iso_df.drop(columns=['startup', 'company'])\n",
    "y = iso_df['startup']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalized\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Rank\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082c184-15a5-416f-92d7-c68383811b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature combination\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model_poly = RandomForestClassifier(random_state=42)\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "# Performance\n",
    "y_pred = model_poly.predict(X_test_poly)\n",
    "print(\"Classification Report with Interaction Features:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c312da7-cd10-4b13-98e8-057ac944b02a",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Non-isolated nodes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7d560-6368-4582-9e80-3d0c2faf9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the feature dataframe\n",
    "data_non_iso = [i for i in data if i['name'] not in isolates]\n",
    "fea_df = generate_feature(G, data)\n",
    "fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5497d6-b29e-40bf-b15c-62d30caaa3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate the class success rate and closeness\n",
    "cla = {}\n",
    "for i in data_non_iso:\n",
    "    for n in i['category_groups']:\n",
    "        if not n in cla.keys():\n",
    "            cla[n] = 1\n",
    "        else:\n",
    "            cla[n] += 1\n",
    "cla_success_rate = success_rate(data_non_iso, cla, 'category_groups')\n",
    "cla_avg_closeness = {}\n",
    "for i in cla.keys():\n",
    "    for n in range(len(fea_df['node_id'])):\n",
    "        if i in fea_df['categories'][n]:\n",
    "            if i in cla_avg_closeness:\n",
    "                cla_avg_closeness[i] += fea_df['closeness'][n]\n",
    "            else:\n",
    "                cla_avg_closeness[i] = fea_df['closeness'][n]\n",
    "for i in cla_avg_closeness:\n",
    "    cla_avg_closeness[i] = cla_avg_closeness[i]/cla[i]\n",
    "\n",
    "\n",
    "avg_cla_sco = []\n",
    "avg_cla_clo = []\n",
    "for i in fea_df['categories']:\n",
    "    cla_rates = [cla_success_rate[n] for n in i]\n",
    "    clo_rates = [cla_avg_closeness[n] for n in i]\n",
    "    if cla_rates:\n",
    "        avg_success_rate = sum(cla_rates) / len(cla_rates)\n",
    "        avg_clo = sum(clo_rates) / len(clo_rates)\n",
    "        avg_cla_sco.append(avg_success_rate)\n",
    "        avg_cla_clo.append(avg_clo)\n",
    "    else:\n",
    "        avg_cla_sco.append(0)\n",
    "        avg_cla_clo.append(0)\n",
    "fea_df['class_score'] = avg_cla_sco\n",
    "fea_df['class_avg_closeness'] = avg_cla_clo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef341248-bcc2-4b4f-98d3-2d94ee1713b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate the location success rate\n",
    "location = {}\n",
    "for i in data_non_iso:\n",
    "    if i['location_groups']:\n",
    "        for n in i['location_groups']:\n",
    "            if not n in location:\n",
    "                location[n] = 1\n",
    "            else:\n",
    "                location[n] += 1\n",
    "loc_success_rate = success_rate(data_non_iso, location, 'location_groups')\n",
    "avg_loc_sco = []\n",
    "for i in data_non_iso:\n",
    "    rates = [loc_success_rate[n] for n in i['location_groups']]\n",
    "    if rates:\n",
    "        avg_success_rate = sum(rates) / len(rates)\n",
    "        avg_loc_sco.append(avg_success_rate)\n",
    "    else:\n",
    "        avg_loc_sco.append(0)\n",
    "fea_df['location_score'] = avg_loc_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c93781-9469-4b17-92ee-ce9436a50d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate the number of employees success rate\n",
    "employees = {}\n",
    "for i in data_non_iso:\n",
    "    if i['num_employees_enum']:\n",
    "        if not i['num_employees_enum'] in employees:\n",
    "            employees[i['num_employees_enum']] = 1\n",
    "        else:\n",
    "            employees[i['num_employees_enum']] += 1\n",
    "emp_success_rate = success_rate(data_non_iso, employees, 'num_employees_enum')\n",
    "avg_emp_sco = []\n",
    "for i in data_non_iso:\n",
    "    if i['num_employees_enum']:\n",
    "        avg_emp_sco.append(emp_success_rate[i['num_employees_enum']])\n",
    "    else:\n",
    "        avg_emp_sco.append(0)\n",
    "fea_df['employees_score'] = avg_emp_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bfcfca-683c-4c92-8ea9-32fabcf4f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate component data\n",
    "node_component_data = components_data(G)\n",
    "comp_success_rate = [node_component_data[node]['component_success_rate'] for node in fea_df['node_id']]\n",
    "comp_size = [node_component_data[node]['component_size'] for node in fea_df['node_id']]\n",
    "fea_df['component_success_rate'] = comp_success_rate\n",
    "fea_df['component_size'] = comp_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99508e0c-34da-420f-ad41-574220acc784",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:20px;\">Training and prediction</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff13ee-ac68-416f-8eba-40001b3a92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = fea_df.drop(columns=['node_id', 'categories', 'component_size'])\n",
    "y = [i['startup'] for i in data_non_iso]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1babb-a4a0-4e15-8a26-072073edd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd2be2-3acb-4461-944a-539f682a7f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Rank\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b082b3-0f21-4e61-b657-a88a58681405",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model_1 = LogisticRegression(max_iter=1000)\n",
    "model_2 = DecisionTreeClassifier()\n",
    "model_3 = RandomForestClassifier()\n",
    "model_4 = SVC(kernel='linear', probability=True)\n",
    "model_5 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "model_4.fit(X_train, y_train)\n",
    "model_5.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "y_pred_3 = model_3.predict(X_test)\n",
    "y_pred_4 = model_4.predict(X_test)\n",
    "y_pred_5 = model_5.predict(X_test)\n",
    "\n",
    "model_1_poly = LogisticRegression()\n",
    "model_2_poly = DecisionTreeClassifier()\n",
    "model_3_poly = RandomForestClassifier()\n",
    "model_4_poly = SVC(kernel='linear', probability=True)\n",
    "model_5_poly = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "model_1_poly.fit(X_train_poly, y_train)\n",
    "model_2_poly.fit(X_train_poly, y_train)\n",
    "model_3_poly.fit(X_train_poly, y_train)\n",
    "model_4_poly.fit(X_train_poly, y_train)\n",
    "model_5_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_1_poly = model_1_poly.predict(X_test_poly)\n",
    "y_pred_2_poly = model_2_poly.predict(X_test_poly)\n",
    "y_pred_3_poly = model_3_poly.predict(X_test_poly)\n",
    "y_pred_4_poly = model_4_poly.predict(X_test_poly)\n",
    "y_pred_5_poly = model_5_poly.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a497a9-11da-4373-ad10-b08cdd23d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pred(model_1, X_test, y_test, y_pred_1, 'Logistic Regression')\n",
    "evaluate_pred(model_2, X_test, y_test, y_pred_2, 'Decision Tree')\n",
    "evaluate_pred(model_3, X_test, y_test, y_pred_3, 'Random Forest')\n",
    "evaluate_pred(model_4, X_test, y_test, y_pred_4, 'SVC')\n",
    "evaluate_pred(model_5, X_test, y_test, y_pred_5, 'K-Nearest Neighbors')\n",
    "print('*******************************************')\n",
    "evaluate_pred(model_1_poly, X_test_poly, y_test, y_pred_1_poly, 'Logistic Regression with Interaction Features')\n",
    "evaluate_pred(model_2_poly, X_test_poly, y_test, y_pred_2_poly, 'Decision Tree with Interaction Features')\n",
    "evaluate_pred(model_3_poly, X_test_poly, y_test, y_pred_3_poly, 'Random Forest with Interaction Features')\n",
    "evaluate_pred(model_4_poly, X_test_poly, y_test, y_pred_4_poly, 'SVC with Interaction Features')\n",
    "evaluate_pred(model_5_poly, X_test_poly, y_test, y_pred_5_poly, 'K-Nearest Neighbors with Interaction Features')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
